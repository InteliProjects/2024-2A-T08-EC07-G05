{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f826d0-2524-4970-8f63-e1e1c881bf32",
   "metadata": {},
   "source": [
    "# Criação, treino e teste do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f76b5-3009-4b77-84f9-560dab31124b",
   "metadata": {},
   "source": [
    "## Instalando bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2ea2a6-9752-4881-8ecb-ab1b846eccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\inteli\\documents\\github\\2024-2a-t08-ec07-g05\\src\\notebooks\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae38060-6475-489d-99d2-e0da38622e69",
   "metadata": {},
   "source": [
    "## Leitura e Verificação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9530c490-88ee-4349-9798-281e222e9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79857831-cd3e-4781-a548-dce9bff84cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEM_FALHA_ROD\n",
      "0.0    64841\n",
      "1.0     4653\n",
      "Name: count, dtype: int64\n",
      "KNR                           0\n",
      "QTD_STATUS_1_OK               0\n",
      "QTD_STATUS_1_NOK              0\n",
      "QTD_STATUS_2_OK               0\n",
      "QTD_STATUS_2_NOK              0\n",
      "QTD_STATUS_718_OK             0\n",
      "QTD_STATUS_718_NOK            0\n",
      "TEMPO_MEDIO                6253\n",
      "MOTOR                     12675\n",
      "COR                       12675\n",
      "QTD_HALLE_                12677\n",
      "QTD_HALLE_AGUA            12677\n",
      "QTD_HALLE_BUY             12677\n",
      "QTD_HALLE_CAB             12677\n",
      "QTD_HALLE_DKA             12677\n",
      "QTD_HALLE_ESPC            12677\n",
      "QTD_HALLE_PROC            12677\n",
      "QTD_HALLE_PROF            12677\n",
      "QTD_HALLE_PVC             12677\n",
      "QTD_HALLE_ROD             12677\n",
      "QTD_HALLE_RUID            12677\n",
      "QTD_HALLE_TLUI            12677\n",
      "QTD_HALLE_ZP5             12677\n",
      "QTD_HALLE_ZP5A            12677\n",
      "QTD_HALLE_ZP6             12677\n",
      "QTD_HALLE_ZP61            12677\n",
      "QTD_HALLE_ZP62            12677\n",
      "QTD_HALLE_ZP7             12677\n",
      "QTD_HALLE_ZP8             12677\n",
      "QTD_HALLE_ZP82            12677\n",
      "QTD_HALLE_ZP8R            12677\n",
      "QTD_SGROUP_#MULTIVALUE    12675\n",
      "QTD_SGROUP_-2             12675\n",
      "QTD_SGROUP_1              12675\n",
      "QTD_SGROUP_133            12675\n",
      "QTD_SGROUP_137            12675\n",
      "QTD_SGROUP_140            12675\n",
      "QTD_SGROUP_2              12675\n",
      "QTD_SGROUP_4              12675\n",
      "QTD_SGROUP_5              12675\n",
      "QTD_SGROUP_9830946        12675\n",
      "TEM_FALHA_ROD             12675\n",
      "dtype: int64\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "TEM_FALHA_ROD\n",
      "0.0    59110\n",
      "1.0     4162\n",
      "Name: count, dtype: int64\n",
      "KNR                       0\n",
      "QTD_STATUS_1_OK           0\n",
      "QTD_STATUS_1_NOK          0\n",
      "QTD_STATUS_2_OK           0\n",
      "QTD_STATUS_2_NOK          0\n",
      "QTD_STATUS_718_OK         0\n",
      "QTD_STATUS_718_NOK        0\n",
      "TEMPO_MEDIO               0\n",
      "MOTOR                     0\n",
      "COR                       0\n",
      "QTD_HALLE_                0\n",
      "QTD_HALLE_BUY             0\n",
      "QTD_HALLE_CAB             0\n",
      "QTD_HALLE_DKA             0\n",
      "QTD_HALLE_ESPC            0\n",
      "QTD_HALLE_PROC            0\n",
      "QTD_HALLE_PROF            0\n",
      "QTD_HALLE_PVC             0\n",
      "QTD_HALLE_RUID            0\n",
      "QTD_HALLE_TLUI            0\n",
      "QTD_HALLE_ZP5             0\n",
      "QTD_HALLE_ZP5A            0\n",
      "QTD_HALLE_ZP6             0\n",
      "QTD_HALLE_ZP61            0\n",
      "QTD_HALLE_ZP62            0\n",
      "QTD_HALLE_ZP7             0\n",
      "QTD_HALLE_ZP82            0\n",
      "QTD_SGROUP_#MULTIVALUE    0\n",
      "QTD_SGROUP_-2             0\n",
      "QTD_SGROUP_1              0\n",
      "QTD_SGROUP_133            0\n",
      "QTD_SGROUP_137            0\n",
      "QTD_SGROUP_140            0\n",
      "QTD_SGROUP_2              0\n",
      "QTD_SGROUP_4              0\n",
      "QTD_SGROUP_5              0\n",
      "QTD_SGROUP_9830946        0\n",
      "TEM_FALHA_ROD             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('DF_KNRS_COMUM_PROCESSADO.parquet')\n",
    "print(df['TEM_FALHA_ROD'].value_counts())  # Verificando a distribuição da variável alvo\n",
    "print(df.isnull().sum())\n",
    "print('\\n----------\\n')\n",
    "\n",
    "df = df.dropna()  # Removendo valores nulos\n",
    "df = df.drop(columns=[\"QTD_HALLE_ROD\", \"QTD_HALLE_AGUA\", \"QTD_HALLE_ZP8\", \"QTD_HALLE_ZP8R\"])\n",
    "\n",
    "print('\\n----------\\n')\n",
    "print(df['TEM_FALHA_ROD'].value_counts())  # Verificando a distribuição da variável alvo\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7708be56-f646-42da-a8f9-224406f32009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências de valor 1 na coluna QTD_HALLE_ESPC: 1409\n"
     ]
    }
   ],
   "source": [
    "qtd_ocorrencias = df[df['QTD_HALLE_ESPC'] > 1].shape[0]\n",
    "print(f\"Ocorrências de valor 1 na coluna QTD_HALLE_ESPC: {qtd_ocorrencias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e807317b-f6b1-459e-a618-3e51ffcfe111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>QTD_STATUS_1_OK</th>\n",
       "      <th>QTD_STATUS_1_NOK</th>\n",
       "      <th>QTD_STATUS_2_OK</th>\n",
       "      <th>QTD_STATUS_2_NOK</th>\n",
       "      <th>QTD_STATUS_718_OK</th>\n",
       "      <th>QTD_STATUS_718_NOK</th>\n",
       "      <th>TEMPO_MEDIO</th>\n",
       "      <th>MOTOR</th>\n",
       "      <th>COR</th>\n",
       "      <th>...</th>\n",
       "      <th>QTD_SGROUP_-2</th>\n",
       "      <th>QTD_SGROUP_1</th>\n",
       "      <th>QTD_SGROUP_133</th>\n",
       "      <th>QTD_SGROUP_137</th>\n",
       "      <th>QTD_SGROUP_140</th>\n",
       "      <th>QTD_SGROUP_2</th>\n",
       "      <th>QTD_SGROUP_4</th>\n",
       "      <th>QTD_SGROUP_5</th>\n",
       "      <th>QTD_SGROUP_9830946</th>\n",
       "      <th>TEM_FALHA_ROD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-5076008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>DHS</td>\n",
       "      <td>0Q0Q</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-5076015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>DHS</td>\n",
       "      <td>0Q0Q</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-0516009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>CWL</td>\n",
       "      <td>5T5T</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-0526019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.416667</td>\n",
       "      <td>DHS</td>\n",
       "      <td>0Q0Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-0526096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>26.416667</td>\n",
       "      <td>DHS</td>\n",
       "      <td>K2K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KNR  QTD_STATUS_1_OK  QTD_STATUS_1_NOK  QTD_STATUS_2_OK  \\\n",
       "0  2023-5076008                0                 0                0   \n",
       "1  2023-5076015                0                 0                0   \n",
       "2  2024-0516009                0                 0               16   \n",
       "3  2024-0526019                0                 0                0   \n",
       "4  2024-0526096                0                 0                4   \n",
       "\n",
       "   QTD_STATUS_2_NOK  QTD_STATUS_718_OK  QTD_STATUS_718_NOK  TEMPO_MEDIO MOTOR  \\\n",
       "0                 0                  1                   2    54.250000   DHS   \n",
       "1                 0                  1                   1    54.250000   DHS   \n",
       "2                 0                 40                   0    54.250000   CWL   \n",
       "3                 0                  1                   0    26.416667   DHS   \n",
       "4                 0                 53                   1    26.416667   DHS   \n",
       "\n",
       "    COR  ...  QTD_SGROUP_-2  QTD_SGROUP_1  QTD_SGROUP_133  QTD_SGROUP_137  \\\n",
       "0  0Q0Q  ...            1.0          16.0             0.0             0.0   \n",
       "1  0Q0Q  ...            1.0           5.0             0.0             0.0   \n",
       "2  5T5T  ...            1.0           5.0             0.0             0.0   \n",
       "3  0Q0Q  ...            0.0           1.0             0.0             0.0   \n",
       "4  K2K2  ...            0.0           2.0             0.0             0.0   \n",
       "\n",
       "   QTD_SGROUP_140  QTD_SGROUP_2  QTD_SGROUP_4  QTD_SGROUP_5  \\\n",
       "0             1.0           8.0           3.0           4.0   \n",
       "1             1.0           4.0           4.0           2.0   \n",
       "2             0.0           5.0           2.0           6.0   \n",
       "3             0.0           3.0           1.0           0.0   \n",
       "4             0.0           1.0           2.0           0.0   \n",
       "\n",
       "   QTD_SGROUP_9830946  TEM_FALHA_ROD  \n",
       "0                 0.0            1.0  \n",
       "1                 0.0            0.0  \n",
       "2                 3.0            0.0  \n",
       "3                 0.0            0.0  \n",
       "4                 0.0            0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6230e2-5f04-4982-96b9-6d8b87fd2862",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1534e9fd-0ea5-48c8-b7fa-700076499a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando variáveis dummies\n",
    "df = pd.get_dummies(df, columns=['COR', 'MOTOR'], drop_first=True)\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "df = df.drop(columns=[\"KNR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0728d-c613-41c0-86ff-0cbe3cd64412",
   "metadata": {},
   "source": [
    "## Balanceamento das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b5860eb-baaa-40cb-8650-ec93578b031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler  # Importa o método RandomUnderSampler para balanceamento de classes\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)  # Inicializa o RandomUnderSampler com uma semente de aleatoriedade fixa\n",
    "\n",
    "X = df.drop(columns=['TEM_FALHA_ROD'])  # Removendo a variável alvo, mantendo apenas as variáveis preditoras\n",
    "y = df['TEM_FALHA_ROD']  # Definindo a variável alvo\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)  # Aplica o balanceamento de classes aos dados, retornando as amostras balanceadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e0369-dc35-4611-a33f-420b359864fe",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a580506-0e4a-4601-8477-016b0c7d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importa a função para dividir os dados em conjuntos de treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  \n",
    "# Divide os dados balanceados em conjuntos de treino (80%) e teste (20%), com uma semente de aleatoriedade fixa para reprodução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384f474-74f4-49e7-9eff-bfb02d435da1",
   "metadata": {},
   "source": [
    "## Redimensionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "696c092c-acb2-4863-9ae2-35b197f871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))  \n",
    "# Altera a forma de X_train para (n amostras, 1, n características) para compatibilidade com redes neurais que esperam uma dimensão adicional\n",
    "\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))  \n",
    "# Altera a forma de X_test de maneira semelhante\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)  \n",
    "# Converte X_train para um array NumPy com tipo de dado float32\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)  \n",
    "# Converte y_train para um array NumPy com tipo de dado float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2858d-ca75-4d6e-a837-c6f4e781a0ae",
   "metadata": {},
   "source": [
    "## Construção dos Modelos (LSTM e GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b850a-75fc-458a-8270-c7d1669228fb",
   "metadata": {},
   "source": [
    "### Modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4f65e3a-c828-4360-b810-2aa6a274e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G05\\src\\notebooks\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential()  # Cria um modelo sequencial, que é uma pilha linear de camadas\n",
    "\n",
    "model_gru.add(GRU(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada GRU com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_gru.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "model_gru.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f69a1d73-5e39-43cb-934b-d8eb3e4bf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5030 - loss: 0.7710 - val_accuracy: 0.4715 - val_loss: 0.7075\n",
      "Epoch 2/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4978 - loss: 0.7282 - val_accuracy: 0.4632 - val_loss: 0.7080\n",
      "Epoch 3/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5014 - loss: 0.7151 - val_accuracy: 0.5045 - val_loss: 0.6941\n",
      "Epoch 4/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5172 - loss: 0.7008 - val_accuracy: 0.5060 - val_loss: 0.6965\n",
      "Epoch 5/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5020 - loss: 0.7085 - val_accuracy: 0.4947 - val_loss: 0.6967\n",
      "Epoch 6/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5126 - loss: 0.7015 - val_accuracy: 0.5113 - val_loss: 0.6942\n",
      "Epoch 7/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 0.6991 - val_accuracy: 0.5068 - val_loss: 0.6920\n",
      "Epoch 8/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 0.7011 - val_accuracy: 0.4842 - val_loss: 0.6945\n",
      "Epoch 9/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5276 - loss: 0.6979 - val_accuracy: 0.5083 - val_loss: 0.6950\n",
      "Epoch 10/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5039 - loss: 0.6987 - val_accuracy: 0.4932 - val_loss: 0.6942\n",
      "Epoch 11/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5188 - loss: 0.6946 - val_accuracy: 0.5240 - val_loss: 0.6949\n",
      "Epoch 12/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5232 - loss: 0.6980 - val_accuracy: 0.4985 - val_loss: 0.6989\n",
      "Epoch 13/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4875 - loss: 0.7006 - val_accuracy: 0.4805 - val_loss: 0.6964\n",
      "Epoch 14/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5139 - loss: 0.6953 - val_accuracy: 0.4947 - val_loss: 0.6969\n",
      "Epoch 15/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5226 - loss: 0.6917 - val_accuracy: 0.4955 - val_loss: 0.6955\n",
      "Epoch 16/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5155 - loss: 0.6934 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
      "Epoch 17/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5178 - loss: 0.6935 - val_accuracy: 0.5068 - val_loss: 0.6950\n",
      "Epoch 18/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5207 - loss: 0.6922 - val_accuracy: 0.5023 - val_loss: 0.6935\n",
      "Epoch 19/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5159 - loss: 0.6908 - val_accuracy: 0.4902 - val_loss: 0.6963\n",
      "Epoch 20/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6918 - val_accuracy: 0.4940 - val_loss: 0.6962\n",
      "Epoch 21/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5251 - loss: 0.6920 - val_accuracy: 0.4745 - val_loss: 0.6971\n",
      "Epoch 22/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5133 - loss: 0.6926 - val_accuracy: 0.4940 - val_loss: 0.6971\n",
      "Epoch 23/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 0.6928 - val_accuracy: 0.4962 - val_loss: 0.6964\n",
      "Epoch 24/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5163 - loss: 0.6909 - val_accuracy: 0.5188 - val_loss: 0.6942\n",
      "Epoch 25/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5083 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6946\n",
      "Epoch 26/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5338 - loss: 0.6906 - val_accuracy: 0.4977 - val_loss: 0.6969\n",
      "Epoch 27/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5204 - loss: 0.6902 - val_accuracy: 0.4970 - val_loss: 0.6965\n",
      "Epoch 28/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5136 - loss: 0.6932 - val_accuracy: 0.4827 - val_loss: 0.6943\n",
      "Epoch 29/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: 0.6924 - val_accuracy: 0.5015 - val_loss: 0.6935\n",
      "Epoch 30/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5189 - loss: 0.6949 - val_accuracy: 0.5128 - val_loss: 0.6956\n",
      "Epoch 31/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5143 - loss: 0.6925 - val_accuracy: 0.4970 - val_loss: 0.6961\n",
      "Epoch 32/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5155 - loss: 0.6918 - val_accuracy: 0.5015 - val_loss: 0.6957\n",
      "Epoch 33/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5278 - loss: 0.6904 - val_accuracy: 0.5158 - val_loss: 0.6939\n",
      "Epoch 34/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5196 - loss: 0.6905 - val_accuracy: 0.5023 - val_loss: 0.6947\n",
      "Epoch 35/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5111 - loss: 0.6902 - val_accuracy: 0.5263 - val_loss: 0.6926\n",
      "Epoch 36/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5236 - loss: 0.6912 - val_accuracy: 0.5203 - val_loss: 0.6910\n",
      "Epoch 37/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5223 - loss: 0.6959 - val_accuracy: 0.5158 - val_loss: 0.6923\n",
      "Epoch 38/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5164 - loss: 0.6919 - val_accuracy: 0.5060 - val_loss: 0.6996\n",
      "Epoch 39/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5157 - loss: 0.6927 - val_accuracy: 0.4977 - val_loss: 0.6962\n",
      "Epoch 40/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5174 - loss: 0.6943 - val_accuracy: 0.4947 - val_loss: 0.6961\n",
      "Epoch 41/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5112 - loss: 0.6955 - val_accuracy: 0.4962 - val_loss: 0.6961\n",
      "Epoch 42/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: 0.6926 - val_accuracy: 0.5150 - val_loss: 0.6937\n",
      "Epoch 43/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5189 - loss: 0.6911 - val_accuracy: 0.5090 - val_loss: 0.6931\n",
      "Epoch 44/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6927 - val_accuracy: 0.4955 - val_loss: 0.6966\n",
      "Epoch 45/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.6943 - val_accuracy: 0.5203 - val_loss: 0.6967\n",
      "Epoch 46/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5130 - loss: 0.6921 - val_accuracy: 0.5098 - val_loss: 0.6931\n",
      "Epoch 47/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 0.6905 - val_accuracy: 0.4925 - val_loss: 0.6940\n",
      "Epoch 48/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5227 - loss: 0.6911 - val_accuracy: 0.4880 - val_loss: 0.6943\n",
      "Epoch 49/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5142 - loss: 0.6909 - val_accuracy: 0.5015 - val_loss: 0.6980\n",
      "Epoch 50/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5288 - loss: 0.6886 - val_accuracy: 0.4917 - val_loss: 0.6956\n",
      "Epoch 51/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5151 - loss: 0.6915 - val_accuracy: 0.5075 - val_loss: 0.6950\n",
      "Epoch 52/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5171 - loss: 0.6921 - val_accuracy: 0.4992 - val_loss: 0.6954\n",
      "Epoch 53/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5218 - loss: 0.6896 - val_accuracy: 0.5023 - val_loss: 0.6938\n",
      "Epoch 54/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 0.6903 - val_accuracy: 0.5120 - val_loss: 0.6925\n",
      "Epoch 55/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.6903 - val_accuracy: 0.5008 - val_loss: 0.6960\n",
      "Epoch 56/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5280 - loss: 0.6908 - val_accuracy: 0.5030 - val_loss: 0.6942\n",
      "Epoch 57/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5215 - loss: 0.6911 - val_accuracy: 0.5090 - val_loss: 0.6928\n",
      "Epoch 58/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5322 - loss: 0.6882 - val_accuracy: 0.5233 - val_loss: 0.6950\n",
      "Epoch 59/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5322 - loss: 0.6886 - val_accuracy: 0.4970 - val_loss: 0.6922\n",
      "Epoch 60/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5214 - loss: 0.6901 - val_accuracy: 0.4977 - val_loss: 0.6934\n",
      "Epoch 61/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6905 - val_accuracy: 0.5068 - val_loss: 0.6912\n",
      "Epoch 62/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5335 - loss: 0.6889 - val_accuracy: 0.5068 - val_loss: 0.6913\n",
      "Epoch 63/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5250 - loss: 0.6885 - val_accuracy: 0.5008 - val_loss: 0.6931\n",
      "Epoch 64/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5213 - loss: 0.6888 - val_accuracy: 0.5015 - val_loss: 0.6917\n",
      "Epoch 65/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6883 - val_accuracy: 0.5030 - val_loss: 0.6924\n",
      "Epoch 66/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6880 - val_accuracy: 0.4985 - val_loss: 0.6940\n",
      "Epoch 67/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 0.6869 - val_accuracy: 0.5045 - val_loss: 0.6927\n",
      "Epoch 68/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5133 - loss: 0.6890 - val_accuracy: 0.5180 - val_loss: 0.6916\n",
      "Epoch 69/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5288 - loss: 0.6898 - val_accuracy: 0.5008 - val_loss: 0.6942\n",
      "Epoch 70/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5207 - loss: 0.6914 - val_accuracy: 0.5165 - val_loss: 0.6924\n",
      "Epoch 71/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5195 - loss: 0.6903 - val_accuracy: 0.5113 - val_loss: 0.6907\n",
      "Epoch 72/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5212 - loss: 0.6909 - val_accuracy: 0.5083 - val_loss: 0.6899\n",
      "Epoch 73/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5272 - loss: 0.6883 - val_accuracy: 0.5368 - val_loss: 0.6901\n",
      "Epoch 74/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5386 - loss: 0.6860 - val_accuracy: 0.5173 - val_loss: 0.6912\n",
      "Epoch 75/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6881 - val_accuracy: 0.5218 - val_loss: 0.6926\n",
      "Epoch 76/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5325 - loss: 0.6853 - val_accuracy: 0.5008 - val_loss: 0.6913\n",
      "Epoch 77/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5213 - loss: 0.6891 - val_accuracy: 0.4947 - val_loss: 0.6953\n",
      "Epoch 78/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 0.6883 - val_accuracy: 0.5135 - val_loss: 0.6963\n",
      "Epoch 79/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5353 - loss: 0.6887 - val_accuracy: 0.5278 - val_loss: 0.6901\n",
      "Epoch 80/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5317 - loss: 0.6849 - val_accuracy: 0.5068 - val_loss: 0.6906\n",
      "Epoch 81/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5393 - loss: 0.6862 - val_accuracy: 0.5173 - val_loss: 0.7027\n",
      "Epoch 82/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5264 - loss: 0.6907 - val_accuracy: 0.5315 - val_loss: 0.6901\n",
      "Epoch 83/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5308 - loss: 0.6876 - val_accuracy: 0.5150 - val_loss: 0.6934\n",
      "Epoch 84/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 0.6895 - val_accuracy: 0.5090 - val_loss: 0.6952\n",
      "Epoch 85/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5353 - loss: 0.6851 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
      "Epoch 86/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5378 - loss: 0.6892 - val_accuracy: 0.4977 - val_loss: 0.6938\n",
      "Epoch 87/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 0.6863 - val_accuracy: 0.5293 - val_loss: 0.6913\n",
      "Epoch 88/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5341 - loss: 0.6879 - val_accuracy: 0.5345 - val_loss: 0.6912\n",
      "Epoch 89/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.6847 - val_accuracy: 0.5345 - val_loss: 0.6912\n",
      "Epoch 90/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5181 - loss: 0.6879 - val_accuracy: 0.5218 - val_loss: 0.6909\n",
      "Epoch 91/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.6813 - val_accuracy: 0.5233 - val_loss: 0.6891\n",
      "Epoch 92/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5392 - loss: 0.6854 - val_accuracy: 0.5345 - val_loss: 0.6913\n",
      "Epoch 93/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5365 - loss: 0.6882 - val_accuracy: 0.5090 - val_loss: 0.6933\n",
      "Epoch 94/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6837 - val_accuracy: 0.5000 - val_loss: 0.6919\n",
      "Epoch 95/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5417 - loss: 0.6840 - val_accuracy: 0.5248 - val_loss: 0.6890\n",
      "Epoch 96/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6856 - val_accuracy: 0.5465 - val_loss: 0.6880\n",
      "Epoch 97/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5371 - loss: 0.6835 - val_accuracy: 0.5285 - val_loss: 0.6901\n",
      "Epoch 98/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5547 - loss: 0.6829 - val_accuracy: 0.5278 - val_loss: 0.6905\n",
      "Epoch 99/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5181 - loss: 0.6880 - val_accuracy: 0.5173 - val_loss: 0.6911\n",
      "Epoch 100/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5335 - loss: 0.6851 - val_accuracy: 0.5413 - val_loss: 0.6876\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo GRU\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db029f-4a19-4ad0-8f5d-740a8a472321",
   "metadata": {},
   "source": [
    "### Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3bcbf2e-7dd0-404f-ad1e-d6166888f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,651</span> (80.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,651\u001b[0m (80.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,651</span> (80.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,651\u001b[0m (80.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir o modelo LSTM\n",
    "model_lstm = Sequential()  # Cria um modelo sequencial para o LSTM\n",
    "\n",
    "# Camada LSTM\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada LSTM com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_lstm.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "# Camada de saída\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "# Compilar o modelo\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia\n",
    "\n",
    "# Resumo do modelo\n",
    "model_lstm.summary()  # Exibe um resumo da arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c05eafc9-416c-49fe-bd21-b6e86a903588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5150 - loss: 0.7090 - val_accuracy: 0.5008 - val_loss: 0.6931\n",
      "Epoch 2/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5081 - loss: 0.7012 - val_accuracy: 0.4827 - val_loss: 0.6959\n",
      "Epoch 3/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5204 - loss: 0.6985 - val_accuracy: 0.5075 - val_loss: 0.6928\n",
      "Epoch 4/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5049 - loss: 0.7001 - val_accuracy: 0.5158 - val_loss: 0.6929\n",
      "Epoch 5/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5380 - loss: 0.6912 - val_accuracy: 0.5375 - val_loss: 0.6903\n",
      "Epoch 6/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 0.6974 - val_accuracy: 0.5480 - val_loss: 0.6892\n",
      "Epoch 7/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5345 - loss: 0.6922 - val_accuracy: 0.5008 - val_loss: 0.6934\n",
      "Epoch 8/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5188 - loss: 0.6951 - val_accuracy: 0.5495 - val_loss: 0.6896\n",
      "Epoch 9/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5137 - loss: 0.6947 - val_accuracy: 0.5255 - val_loss: 0.6929\n",
      "Epoch 10/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5204 - loss: 0.6971 - val_accuracy: 0.5075 - val_loss: 0.6910\n",
      "Epoch 11/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5153 - loss: 0.6949 - val_accuracy: 0.5533 - val_loss: 0.6865\n",
      "Epoch 12/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5364 - loss: 0.6889 - val_accuracy: 0.5458 - val_loss: 0.6876\n",
      "Epoch 13/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5625 - loss: 0.6840 - val_accuracy: 0.5203 - val_loss: 0.6855\n",
      "Epoch 14/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5538 - loss: 0.6860 - val_accuracy: 0.5195 - val_loss: 0.6878\n",
      "Epoch 15/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5603 - loss: 0.6840 - val_accuracy: 0.5826 - val_loss: 0.6744\n",
      "Epoch 16/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6217 - loss: 0.6624 - val_accuracy: 0.7102 - val_loss: 0.6508\n",
      "Epoch 17/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.6285 - val_accuracy: 0.7658 - val_loss: 0.5825\n",
      "Epoch 18/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7606 - loss: 0.5801 - val_accuracy: 0.8378 - val_loss: 0.5435\n",
      "Epoch 19/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.5479 - val_accuracy: 0.9474 - val_loss: 0.4706\n",
      "Epoch 20/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.4839 - val_accuracy: 0.9767 - val_loss: 0.4359\n",
      "Epoch 21/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.4396 - val_accuracy: 0.9617 - val_loss: 0.3674\n",
      "Epoch 22/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8852 - loss: 0.4036 - val_accuracy: 0.9002 - val_loss: 0.3826\n",
      "Epoch 23/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.3705 - val_accuracy: 0.9707 - val_loss: 0.3141\n",
      "Epoch 24/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.3098 - val_accuracy: 0.9715 - val_loss: 0.2879\n",
      "Epoch 25/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2881 - val_accuracy: 1.0000 - val_loss: 0.2143\n",
      "Epoch 26/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.2507 - val_accuracy: 0.9992 - val_loss: 0.1937\n",
      "Epoch 27/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.2332 - val_accuracy: 0.9790 - val_loss: 0.2445\n",
      "Epoch 28/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.2576 - val_accuracy: 0.9895 - val_loss: 0.1535\n",
      "Epoch 29/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.2075 - val_accuracy: 0.9865 - val_loss: 0.1432\n",
      "Epoch 30/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.2010 - val_accuracy: 0.9932 - val_loss: 0.1382\n",
      "Epoch 31/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1873 - val_accuracy: 0.9760 - val_loss: 0.1304\n",
      "Epoch 32/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1688 - val_accuracy: 0.9587 - val_loss: 0.1253\n",
      "Epoch 33/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9566 - loss: 0.1589 - val_accuracy: 0.9572 - val_loss: 0.1477\n",
      "Epoch 34/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1614 - val_accuracy: 0.9737 - val_loss: 0.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1713 - val_accuracy: 0.9737 - val_loss: 0.1158\n",
      "Epoch 36/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1597 - val_accuracy: 0.9925 - val_loss: 0.1012\n",
      "Epoch 37/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9564 - loss: 0.1442 - val_accuracy: 0.9775 - val_loss: 0.1143\n",
      "Epoch 38/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.1477 - val_accuracy: 0.9857 - val_loss: 0.0978\n",
      "Epoch 39/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1439 - val_accuracy: 0.9805 - val_loss: 0.0994\n",
      "Epoch 40/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1079 - val_accuracy: 0.9752 - val_loss: 0.0764\n",
      "Epoch 41/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9503 - loss: 0.1468 - val_accuracy: 0.9467 - val_loss: 0.0998\n",
      "Epoch 42/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.1190 - val_accuracy: 0.9865 - val_loss: 0.0477\n",
      "Epoch 43/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.1202 - val_accuracy: 0.9812 - val_loss: 0.0688\n",
      "Epoch 44/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.1117 - val_accuracy: 0.9700 - val_loss: 0.1071\n",
      "Epoch 45/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1325 - val_accuracy: 0.9827 - val_loss: 0.0633\n",
      "Epoch 46/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.1157 - val_accuracy: 1.0000 - val_loss: 0.0343\n",
      "Epoch 47/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.0929 - val_accuracy: 0.9625 - val_loss: 0.0738\n",
      "Epoch 48/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.0978 - val_accuracy: 0.9992 - val_loss: 0.0648\n",
      "Epoch 49/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.1120 - val_accuracy: 0.9887 - val_loss: 0.0741\n",
      "Epoch 50/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.1199 - val_accuracy: 0.9782 - val_loss: 0.0582\n",
      "Epoch 51/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.1356 - val_accuracy: 0.9880 - val_loss: 0.0720\n",
      "Epoch 52/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1260 - val_accuracy: 0.9677 - val_loss: 0.0784\n",
      "Epoch 53/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.1119 - val_accuracy: 0.9895 - val_loss: 0.0449\n",
      "Epoch 54/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.1038 - val_accuracy: 0.9835 - val_loss: 0.0541\n",
      "Epoch 55/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.0802 - val_accuracy: 1.0000 - val_loss: 0.0493\n",
      "Epoch 56/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.1210 - val_accuracy: 0.9917 - val_loss: 0.0892\n",
      "Epoch 57/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9497 - loss: 0.1396 - val_accuracy: 0.9872 - val_loss: 0.0684\n",
      "Epoch 58/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9345 - loss: 0.1659 - val_accuracy: 0.9842 - val_loss: 0.0655\n",
      "Epoch 59/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9610 - loss: 0.1095 - val_accuracy: 0.9565 - val_loss: 0.0874\n",
      "Epoch 60/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9532 - loss: 0.1370 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "Epoch 61/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0907 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
      "Epoch 62/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.0986 - val_accuracy: 0.9842 - val_loss: 0.0959\n",
      "Epoch 63/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9562 - loss: 0.1199 - val_accuracy: 0.9812 - val_loss: 0.0607\n",
      "Epoch 64/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0776 - val_accuracy: 0.9827 - val_loss: 0.0682\n",
      "Epoch 65/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0865 - val_accuracy: 0.9902 - val_loss: 0.0556\n",
      "Epoch 66/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9622 - loss: 0.1050 - val_accuracy: 0.9354 - val_loss: 0.1036\n",
      "Epoch 67/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9382 - loss: 0.1417 - val_accuracy: 0.9932 - val_loss: 0.0486\n",
      "Epoch 68/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.1219 - val_accuracy: 0.9992 - val_loss: 0.0814\n",
      "Epoch 69/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1300 - val_accuracy: 0.9700 - val_loss: 0.1382\n",
      "Epoch 70/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1368 - val_accuracy: 0.9737 - val_loss: 0.0808\n",
      "Epoch 71/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.0855 - val_accuracy: 0.9955 - val_loss: 0.0474\n",
      "Epoch 72/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.0834 - val_accuracy: 0.9715 - val_loss: 0.0901\n",
      "Epoch 73/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.1136 - val_accuracy: 0.9835 - val_loss: 0.0478\n",
      "Epoch 74/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.1095 - val_accuracy: 1.0000 - val_loss: 0.0622\n",
      "Epoch 75/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0705 - val_accuracy: 0.9760 - val_loss: 0.0593\n",
      "Epoch 76/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1420 - val_accuracy: 0.9775 - val_loss: 0.0635\n",
      "Epoch 77/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1351 - val_accuracy: 0.9962 - val_loss: 0.0430\n",
      "Epoch 78/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.1337 - val_accuracy: 0.9685 - val_loss: 0.0689\n",
      "Epoch 79/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0945 - val_accuracy: 0.9917 - val_loss: 0.0265\n",
      "Epoch 80/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.0890 - val_accuracy: 0.9369 - val_loss: 0.0628\n",
      "Epoch 81/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.0978 - val_accuracy: 0.9707 - val_loss: 0.0961\n",
      "Epoch 82/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9558 - loss: 0.1252 - val_accuracy: 1.0000 - val_loss: 0.0262\n",
      "Epoch 83/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9697 - loss: 0.0822 - val_accuracy: 0.9985 - val_loss: 0.0204\n",
      "Epoch 84/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.1006 - val_accuracy: 0.9992 - val_loss: 0.0390\n",
      "Epoch 85/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0808 - val_accuracy: 0.9550 - val_loss: 0.0860\n",
      "Epoch 86/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.0987 - val_accuracy: 0.9264 - val_loss: 0.2417\n",
      "Epoch 87/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.1764 - val_accuracy: 0.9452 - val_loss: 0.1250\n",
      "Epoch 88/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.1837 - val_accuracy: 0.9887 - val_loss: 0.0559\n",
      "Epoch 89/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.1275 - val_accuracy: 0.9865 - val_loss: 0.0399\n",
      "Epoch 90/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.1077 - val_accuracy: 0.9324 - val_loss: 0.1561\n",
      "Epoch 91/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.1528 - val_accuracy: 0.9955 - val_loss: 0.0309\n",
      "Epoch 92/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1024 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
      "Epoch 93/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0797 - val_accuracy: 0.9910 - val_loss: 0.0215\n",
      "Epoch 94/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0585 - val_accuracy: 1.0000 - val_loss: 0.0519\n",
      "Epoch 95/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0786 - val_accuracy: 0.9670 - val_loss: 0.0478\n",
      "Epoch 96/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0687 - val_accuracy: 0.9287 - val_loss: 0.1934\n",
      "Epoch 97/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9359 - loss: 0.1754 - val_accuracy: 0.9452 - val_loss: 0.1291\n",
      "Epoch 98/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.1959 - val_accuracy: 0.9662 - val_loss: 0.0916\n",
      "Epoch 99/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.1064 - val_accuracy: 0.9767 - val_loss: 0.0735\n",
      "Epoch 100/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1085 - val_accuracy: 0.9805 - val_loss: 0.0588\n",
      "Epoch 101/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0764 - val_accuracy: 0.9805 - val_loss: 0.0557\n",
      "Epoch 102/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0777 - val_accuracy: 0.9842 - val_loss: 0.0472\n",
      "Epoch 103/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0799 - val_accuracy: 0.9850 - val_loss: 0.0364\n",
      "Epoch 104/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.0837 - val_accuracy: 0.9782 - val_loss: 0.0596\n",
      "Epoch 105/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0676 - val_accuracy: 0.9992 - val_loss: 0.0075\n",
      "Epoch 106/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9728 - loss: 0.0815 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
      "Epoch 107/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0851 - val_accuracy: 1.0000 - val_loss: 0.0161\n",
      "Epoch 108/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.0844 - val_accuracy: 0.9985 - val_loss: 0.0334\n",
      "Epoch 109/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9601 - loss: 0.0880 - val_accuracy: 0.9977 - val_loss: 0.0123\n",
      "Epoch 110/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9549 - loss: 0.0875 - val_accuracy: 0.9850 - val_loss: 0.0425\n",
      "Epoch 111/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0823 - val_accuracy: 0.9790 - val_loss: 0.0576\n",
      "Epoch 112/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.0930 - val_accuracy: 0.9797 - val_loss: 0.0586\n",
      "Epoch 113/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.0775 - val_accuracy: 0.9572 - val_loss: 0.0751\n",
      "Epoch 114/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9617 - loss: 0.0926 - val_accuracy: 0.9865 - val_loss: 0.0487\n",
      "Epoch 115/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.0684 - val_accuracy: 0.9865 - val_loss: 0.0338\n",
      "Epoch 116/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.0951 - val_accuracy: 0.9602 - val_loss: 0.0752\n",
      "Epoch 117/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.0790 - val_accuracy: 0.9459 - val_loss: 0.1207\n",
      "Epoch 118/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1182 - val_accuracy: 0.9647 - val_loss: 0.0419\n",
      "Epoch 119/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0771 - val_accuracy: 0.9745 - val_loss: 0.0710\n",
      "Epoch 120/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.0676 - val_accuracy: 0.9745 - val_loss: 0.0701\n",
      "Epoch 121/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0800 - val_accuracy: 0.9745 - val_loss: 0.0869\n",
      "Epoch 122/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0741 - val_accuracy: 1.0000 - val_loss: 0.0186\n",
      "Epoch 123/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.0748 - val_accuracy: 0.9992 - val_loss: 0.0206\n",
      "Epoch 124/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0762 - val_accuracy: 0.9302 - val_loss: 0.0867\n",
      "Epoch 125/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9648 - loss: 0.0940 - val_accuracy: 0.9730 - val_loss: 0.0683\n",
      "Epoch 126/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0632 - val_accuracy: 0.9685 - val_loss: 0.0815\n",
      "Epoch 127/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.0807 - val_accuracy: 0.9842 - val_loss: 0.0462\n",
      "Epoch 128/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0743 - val_accuracy: 0.9977 - val_loss: 0.0188\n",
      "Epoch 129/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9668 - loss: 0.0860 - val_accuracy: 0.9505 - val_loss: 0.0724\n",
      "Epoch 130/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.0162\n",
      "Epoch 131/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.0983 - val_accuracy: 0.9602 - val_loss: 0.0739\n",
      "Epoch 132/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1307 - val_accuracy: 0.9865 - val_loss: 0.0280\n",
      "Epoch 133/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.0880 - val_accuracy: 0.9782 - val_loss: 0.0481\n",
      "Epoch 134/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.0798 - val_accuracy: 0.9737 - val_loss: 0.0395\n",
      "Epoch 135/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.0770 - val_accuracy: 0.9790 - val_loss: 0.0579\n",
      "Epoch 136/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9410 - loss: 0.1527 - val_accuracy: 0.9865 - val_loss: 0.0333\n",
      "Epoch 137/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.0824 - val_accuracy: 0.9625 - val_loss: 0.0612\n",
      "Epoch 138/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1080 - val_accuracy: 0.9587 - val_loss: 0.0832\n",
      "Epoch 139/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.1319 - val_accuracy: 0.9565 - val_loss: 0.0592\n",
      "Epoch 140/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.0800 - val_accuracy: 0.9782 - val_loss: 0.0593\n",
      "Epoch 141/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0769 - val_accuracy: 0.9865 - val_loss: 0.0385\n",
      "Epoch 142/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0791 - val_accuracy: 0.9797 - val_loss: 0.0564\n",
      "Epoch 143/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.0855 - val_accuracy: 0.9707 - val_loss: 0.0615\n",
      "Epoch 144/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.1139 - val_accuracy: 0.9797 - val_loss: 0.0458\n",
      "Epoch 145/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9620 - loss: 0.1103 - val_accuracy: 0.9332 - val_loss: 0.0813\n",
      "Epoch 146/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1153 - val_accuracy: 0.9782 - val_loss: 0.0617\n",
      "Epoch 147/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.0902 - val_accuracy: 0.9414 - val_loss: 0.1327\n",
      "Epoch 148/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9510 - loss: 0.1187 - val_accuracy: 0.9610 - val_loss: 0.0841\n",
      "Epoch 149/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1208 - val_accuracy: 0.9797 - val_loss: 0.0623\n",
      "Epoch 150/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0840 - val_accuracy: 0.9887 - val_loss: 0.0276\n",
      "Epoch 151/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0783 - val_accuracy: 0.9902 - val_loss: 0.0538\n",
      "Epoch 152/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.0915 - val_accuracy: 0.9865 - val_loss: 0.0422\n",
      "Epoch 153/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0726 - val_accuracy: 0.9992 - val_loss: 0.0282\n",
      "Epoch 154/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.0754 - val_accuracy: 0.9640 - val_loss: 0.0595\n",
      "Epoch 155/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0668 - val_accuracy: 0.9835 - val_loss: 0.0423\n",
      "Epoch 156/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.1193 - val_accuracy: 0.9887 - val_loss: 0.0387\n",
      "Epoch 157/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.0599 - val_accuracy: 0.9339 - val_loss: 0.1357\n",
      "Epoch 158/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9510 - loss: 0.1322 - val_accuracy: 0.9617 - val_loss: 0.1011\n",
      "Epoch 159/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.0849 - val_accuracy: 0.9970 - val_loss: 0.0118\n",
      "Epoch 160/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0693 - val_accuracy: 0.9767 - val_loss: 0.0798\n",
      "Epoch 161/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9449 - loss: 0.1688 - val_accuracy: 0.9857 - val_loss: 0.0471\n",
      "Epoch 162/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0888 - val_accuracy: 0.9812 - val_loss: 0.0475\n",
      "Epoch 163/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1247 - val_accuracy: 1.0000 - val_loss: 0.0433\n",
      "Epoch 164/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.0851 - val_accuracy: 0.9557 - val_loss: 0.1148\n",
      "Epoch 165/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9648 - loss: 0.1003 - val_accuracy: 0.9992 - val_loss: 0.0211\n",
      "Epoch 166/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9651 - loss: 0.0934 - val_accuracy: 1.0000 - val_loss: 0.0236\n",
      "Epoch 167/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1169 - val_accuracy: 0.9722 - val_loss: 0.1129\n",
      "Epoch 168/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.1498 - val_accuracy: 0.9895 - val_loss: 0.0596\n",
      "Epoch 169/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1474 - val_accuracy: 0.9842 - val_loss: 0.0537\n",
      "Epoch 170/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.0912 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
      "Epoch 171/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0791 - val_accuracy: 0.9640 - val_loss: 0.0977\n",
      "Epoch 172/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1323 - val_accuracy: 0.9737 - val_loss: 0.0635\n",
      "Epoch 173/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1171 - val_accuracy: 0.9992 - val_loss: 0.0307\n",
      "Epoch 174/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0707 - val_accuracy: 0.9865 - val_loss: 0.0407\n",
      "Epoch 175/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0912 - val_accuracy: 1.0000 - val_loss: 0.0378\n",
      "Epoch 176/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9640 - loss: 0.0900 - val_accuracy: 0.9790 - val_loss: 0.0713\n",
      "Epoch 177/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9562 - loss: 0.1144 - val_accuracy: 0.9962 - val_loss: 0.0562\n",
      "Epoch 178/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.0883 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
      "Epoch 179/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0942 - val_accuracy: 0.9865 - val_loss: 0.0324\n",
      "Epoch 180/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1014 - val_accuracy: 0.9977 - val_loss: 0.0302\n",
      "Epoch 181/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.0994 - val_accuracy: 0.9992 - val_loss: 0.0259\n",
      "Epoch 182/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1248 - val_accuracy: 1.0000 - val_loss: 0.0197\n",
      "Epoch 183/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.0606 - val_accuracy: 0.9812 - val_loss: 0.0598\n",
      "Epoch 184/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.1008 - val_accuracy: 0.9955 - val_loss: 0.0284\n",
      "Epoch 185/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.1047 - val_accuracy: 0.9722 - val_loss: 0.0604\n",
      "Epoch 186/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.1030 - val_accuracy: 0.9865 - val_loss: 0.0450\n",
      "Epoch 187/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0505 - val_accuracy: 0.9910 - val_loss: 0.0876\n",
      "Epoch 188/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.1476 - val_accuracy: 0.9234 - val_loss: 0.1309\n",
      "Epoch 189/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1509 - val_accuracy: 0.9339 - val_loss: 0.1388\n",
      "Epoch 190/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9551 - loss: 0.1104 - val_accuracy: 1.0000 - val_loss: 0.0253\n",
      "Epoch 191/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0653 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 192/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0582 - val_accuracy: 0.9302 - val_loss: 0.1260\n",
      "Epoch 193/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.0802 - val_accuracy: 0.9550 - val_loss: 0.0790\n",
      "Epoch 194/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 195/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.0692 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 196/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.1112 - val_accuracy: 0.9977 - val_loss: 0.0411\n",
      "Epoch 197/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1396 - val_accuracy: 0.9745 - val_loss: 0.0779\n",
      "Epoch 198/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.0923 - val_accuracy: 0.9422 - val_loss: 0.0762\n",
      "Epoch 199/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 0.0774 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 200/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0528 - val_accuracy: 0.9865 - val_loss: 0.0209\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo LSTM\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38966e17-13f4-4b10-b17a-54c1db1630c4",
   "metadata": {},
   "source": [
    "## Avaliando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f15b60-20f0-40c2-a42c-53faf4da7886",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b40bc0c2-f0e2-44c8-a0f6-96fa24e10ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6923\n",
      "Test Loss GRU: 0.6931670904159546\n",
      "Test Accuracy GRU: 0.5369369387626648\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.63      0.58       841\n",
      "         1.0       0.54      0.44      0.48       824\n",
      "\n",
      "    accuracy                           0.54      1665\n",
      "   macro avg       0.54      0.54      0.53      1665\n",
      "weighted avg       0.54      0.54      0.53      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converter X_test e y_test para float32\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "y_test = np.array(y_test).astype('float32')\n",
    "\n",
    "# Avaliar o modelo GRU com os dados de teste\n",
    "loss_gru, accuracy_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Test Loss GRU: {loss_gru}')\n",
    "print(f'Test Accuracy GRU: {accuracy_gru}')\n",
    "\n",
    "# Fazer previsões com o modelo GRU\n",
    "y_pred_gru = model_gru.predict(X_test)\n",
    "y_pred_gru = (y_pred_gru > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_gru))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafc2ab-a9ce-41fb-80fd-f888c785378d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61fd51a9-532b-42a9-b8d9-fe744cc92c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.9537 - loss: 0.1107\n",
      "Test Loss LSTM: 0.09792882204055786\n",
      "Test Accuracy LSTM: 0.9615615606307983\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       841\n",
      "         1.0       1.00      0.92      0.96       824\n",
      "\n",
      "    accuracy                           0.96      1665\n",
      "   macro avg       0.96      0.96      0.96      1665\n",
      "weighted avg       0.96      0.96      0.96      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo LSTM com os dados de teste\n",
    "loss_lstm, accuracy_lstm = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Loss LSTM: {loss_lstm}')\n",
    "print(f'Test Accuracy LSTM: {accuracy_lstm}')\n",
    "\n",
    "# Fazer previsões com o modelo LSTM\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
